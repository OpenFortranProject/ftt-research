\section{Motivation}

The concepts in this paper were motivated by problems encountered during
the development of PetaVision, a C++ software framework designed for simulating
large networks of spiking neurons in the visual cortex of primates.  PetaVision
was designed to run on massively parallel hardware architectures and a primitive
version of PetaVision achieved over a Petaflop/s of sustained single precision
performance on Roadrunner, the fastest computer in the world for a brief
period of time.

Describe neural layers, spiking neurons, synaptic connections, weights,
and plasticity.  Reference Heubel.

Give a simple 1D (cartoon) example of connections within a neural network in
Figure 1.  Describe the size of visual cortex in terms of the number of neurons,
the number of synaptic connections, and performance.  Reference SC Gorden Bell
paper from IBM.

The LOPe programming model restricts the programmer --- while implementing a stencil
algorithm --- to a local view of the array index space.  Within a concurrent function,
only the local array element plus a small halo region is visible to the programmer.
This reduces complexity by all boundary conditions and processor topology information
from the algorithm implementation.  This reduction in complexity reduces programming
errors.  While developing the convolution example described later in the paper we
made an indexing error in applying the 2D stencil loops in the standard serial 
Fortran test implementation.  This error required over 3 hours of programming time
to repair.  First the error had to be isolated to the function implementing the
convolution (it was first thought to be in the complicated tiff image output routine
as the convolution code was ``thought'' to be too simple to wrong.  Then the index
error has to be understood.  As will be seen, LOPe makes it more difficult to make
these errors as Fortran array intrics can be used.  In some instance, the restricted
semantics of LOPe allows the compiler to catch errors (e.g., some errors involving
race conditions).


\subsection{Coarray Fortran Comparison}

Below is the motivational example from the original Numrich and Reic paper.
{NOTE: This should sortof/kindof show how it would work between nodes?  Next
section shows OpenMP example for parallelism at the thread level.}

{\small
\begin{verbatim}

subroutine laplace (nrow,ncol,u)
   integer, intent(in) real, intent(inout) real integer
   ! that refers to the current image
   left = me-1
   if (me == 1) left = ncol
   right = me + 1
   if (me == ncol) right = 1
   call sync_all( (/left,right/) ) ! Wait if left and right
   ! have not already reached here
   new_u(1:nrow)=new_u(1:nrow)+u(1:nrow)[left]+u(1:nrow)[right]
   call sync_all( (/left,right/) )
   u(1:nrow) = new_u(1:nrow) - 4.0*u(1:nrow) end subroutine laplace

\end{verbatim}
}


Below is the equivalent implementation in LOPe.


{\small
\begin{verbatim}

pure CONCURRENT subroutine laplace(U)
   real, intent(inout), HALO(-1:*:1,-1:*:1) :: U(0:,0:)

   U(0:0) = U(-1,0) + U(+1,0) + U(0,-1) + U(0,+1) - 3*U(0,0)

end subroutine laplace


\end{verbatim}
}

NOTE: Following not a criticism of CAF as CAF is a general purpose parallel
programming language and LOPe only pertains to the halo parallel pattern.

\subsubsection{Improvements}
\begin{itemize}

\item
LOPe requires that the implementation of the algorithm to be separate from the
call to effect the halo transfer.  Removing boundary condition specification
(e.g., the cyclic boundary conditions implemented in the CAF example) from the
algorithm allows the boundary conditions to be changed and without changing
algorithm code.

\item
LOPe applies the transfer of halo memory across multiple (possibly) levels of
memory with the intrinsic {\tt transfer\_halo} function (not shown here).  Thus
the LOPe algorithm can be run on a machine with many interconnected nodes, each
containing hybrid processor cores.  The coarray example can only be run on
multiple nodes (called images in Fortran) without accelerator cores.

\item
The algorithm implementation is separate from user-specified synchronization,
e.g., {\tt call sync\_all}.  In LOPe, synchronization is subsummed in the
semantics of the CONCURRENT attribute and the {\tt transfer\_halo} function.

\item
The algorithm implementation is separate from any specification as to where the
array memory is located.  The CAF example explicity denotes where memory is
located with the {\tt [left]} and {\tt [right]} syntax where left and right
specifiy a processor topology.

\item
The algorithm implementation is separate from any specification as to where the
algorithm is to be executed.  The CAF example explicity denotes where a statement is to
executed with control flow construct like {\tt if (me == 1)}.

\item
The LOPe implementation is easier to understand and frequently follows the
mathematical algorithm directly.  For example, the CAF example adds 4 neighbors
plus the center value to make the implementation with direct remote coarray
access possible, while the LOPe example is able to implement the same algorithm
with fewer operations by adding 4 neighbors (not including the center array
element) and then only subtracting 3 center values.

\item
The semantics of LOPe makes explicit management of array temporaries (e.g., {\tt
  u} and {\tt new\_u} by programmers unnecessary (though still possible).
Because in LOPe the halo region is a language construct, the compiler is better
able to manage temporary buffers than users on the target hardware platform.

\end{itemize}

\subsubsection{Errors that are constrained by the language}
\begin{itemize}

\item
A programmer is not able to store data to the halo region.  If this were
allowed, one thread could overwrite another threads data at undefined times.
The compiler is able to catch this class of error.

\item
A programmer can't make indexing errors in a concurrent routine by going out of
bounds of the array plus halo memory.  The compiler is able to catch this class of
error at compile time unless the halo shape is assumed (e.g., HALO(:,:)).

\item
A programmer is not able to cause race conditions by forgetting to create and
use temporary arrays properly.  In LOPe it is the comilers responsibility to
store data in temporary memory.

\item
A programmer can't make synchronization errors as synchronization is implicit in
the CONCURRENT attribute.  A thread running a CONCURRENT procedure is provided
with a copy of it's array element (plus halo) that is consistent with the state
of memory at the time of invocation of procedure.  Stores to an individual
thread's array element (by that thread) is never visible to other threads.
It is possible to relax this restraint with a halo synchronization intrisic.
However, LOPE encourages the creation of small functions and lets the compiler
fuse the procedures together and provide the necessary synchronization.

\end{itemize}

Please note that this example is somewhat unfair because in practice CAF is usually
refactored in a locally oriented way by so that communication and
synchronization separated into separate procedures.  Locally-oriented programming should be viewed as programming methodology with LOPe as a particular instance.

This is the normal way that large complex MPI and CAF programs are implemented, i.e., using
halo cells.  LOPe proposes to formalize this common pattern into the Fortran
language providing the compiler information in order to spread computation over
more hardware resources and reduce complexity for the programmer.


\subsection{OpenMP Comparision}

The coarray Fortran example shows how LOPe 
