\subsection{Comparison to Coarray Fortran}

LOPe provides a purely \emph{local} viewpoint; the programmer is only provided read and write access
to the local array element and read access to a small halo region surrounding the local element.
There is simply \emph{no} mechanism provided for the programmer to even know \emph{where} the local
element is in the context of the broader array.  On a distributed memory architecture, the halo
elements may not even be physically located on the same processor.  If executed on a cluster
containing hybrid processing elements (e.g. GPUs), the halo elements may be as far as three hops
away: one to get to the host processor and another two to get to memory on the hybrid processor
executing on another distributed memory node.  LOPe provides a complete separation between algorithm
development and memory management (synchronization between memory copies of the same logical
array region covered by halos).  By explicitly describing the existance and size of an array's halo
region, the compiler is provided with enough information to manage most of the hard and detailed
work involved in memory transfer and synchronization.  Additionally, the semantics of the LOPe
execution model remove the possibility of race conditions developing during execution of a
concurrent procedure.

We emphasize some of these advantages by comparing the \texttt{Laplace} implementation with the
implementation of the same algorithm from the original Numrich and Reid paper first describing
coarrays in Fortran.  We should point out that this comparison is somewhat unfair, because Numrich
and Reid were introducing coarray notation for transferring memory on distributed memory
architectures, not demonstrating how ideally one should use coarrays within a large application.
%%Please note that this example is somewhat unfair because in practice CAF is usually refactored in a locally oriented way by so that communication and synchronization separated into separate procedures.  Locally-oriented programming should be viewed as programming methodology with LOPe as a particular instance.
However this example serves
to highlight some of the advantages of LOPe and CAFe as introduced above.  Note that in the coarray
example shown below, type declarations have been removed to save space:
{\small \begin{verbatim}
  subroutine Laplace (nrow,ncol,U)
    left = me-1      ! me refers to the current image
    if (me == 1) left = ncol
    right = me + 1
    if (me == ncol) right = 1
    call sync_all( [left,right] )   ! Wait for left and right
    new_u(1:nrow) = new_u(1:nrow) + u(1:nrow)[left] + u(1:nrow)[right]
    call sync_all( [left,right] )
    u(1:nrow) = new_u(1:nrow) - 4.0*u(1:nrow)
  end subroutine
\end{verbatim}}

The advantages of LOPe and CAFe over this example are now described.  Please note that the following
is not a criticism of coarray Fortran as CAF is a general purpose parallel programming language and
LOPe only pertains to the halo pattern most useful in the implementation of stencil-based algorithms.

\subsubsection{LOPe advantages.}
\begin{itemize}

\item
LOPe requires the implementation of the algorithm to be separate from the call to effect the halo
transfer.  Removing boundary condition specification (e.g., the cyclic boundary conditions
implemented in the CAF example) from the algorithm allows the boundary conditions to be changed
without changing algorithm code.

\item
LOPe applies the transfer of halo memory across possibly multiple levels of memory with the LOPe
intrinsic \texttt{TRANSFER\_HALO} function.  Thus the LOPe algorithm can be run on a machine with
many interconnected nodes, each containing hybrid processor cores.  The coarray example can only be
run on multiple nodes without accelerator cores.

\item
Algorithm implementation is separate from user-specified synchronization, e.g., \texttt{call
  sync\_all}.  In LOPe, synchronization is subsummed in the semantics of the \texttt{CONCURRENT}
attribute and the \texttt{TRANSFER\_HALO} function call.

\item
The algorithm implementation is separate from any specification as to where the array
memory is located.  The CAF example explicity denotes where memory is located with the
\texttt{[left]} and \texttt{[right]} syntax where left and right specifiy a processor
topology.

\item
The algorithm implementation is separate from any specification as to where the algorithm
is to be executed.  The CAF example explicity denotes where a statement is to executed
with control flow construct like \texttt{if (me == 1)}.

\item
The LOPe implementation is easier to understand and frequently follows the mathematical algorithm
directly.  For example, the CAF implementation of Numrich and Reid adds 4 neighbors plus the center
value to make the implementation with direct remote coarray access possible, while the LOPe example
is able to implement the same algorithm with one statement and no intervening synchronization.

\item
The semantics of LOPe makes explicit management of array temporaries (e.g., \texttt{u} and
\texttt{new\_u} by the programmer unnecessary (though still possible).  Because in LOPe the
halo region is a language construct, the compiler is better able to manage temporary
buffers than users on the target hardware platform.

\end{itemize}

\subsubsection{Errors that are constrained by the language.}
\begin{itemize}

\item
A programmer is not able to store data to the halo region during execution of a LOPe concurrent
function.  If this were allowed, one thread could overwrite another threads data at undefined times.
The compiler is able to catch this class of error.

\item
A programmer can't make indexing errors in a concurrent routine by going out of bounds of the array
plus halo memory.  The compiler is able to catch this class of error at compile time as long as
compile-time constants are used to specify halo sizes.

\item
A programmer is not able to cause race conditions by forgetting to create and use temporary arrays
properly.  In LOPe it is the compilers responsibility to store data in temporary memory.

\item
A programmer can't make synchronization errors as synchronization is implicit in the
\texttt{CONCURRENT} attribute.  A thread running a concurrent procedure is provided with a copy of
it's local array element plus halo that is consistent with the state of memory \emph{at the time of
  invocation of the procedure}.  Stores to an individual thread's local array element (by that
thread) is never visible to other threads.  LOPE encourages the creation of small functions and lets
the compiler fuse the functions together to improve performance and to provide necessary
synchronization.

\end{itemize}
