\section{Conclusions}

Fortran is a general-purpose programming language and is extremely important to the
scientific and high performance computing (HPC) community.  While new code development is
often in languages other than Fortran, such as C++, Fortran usage in terms of CPU hours on
HPC platforms remains as high as ??? \cite{Yellick::language:breakdown}.  Fortran will be
with us well into the future as the lifetime of important scientific applications is
measured in decades and Fortran usage dominates in scientific communitities that are
critical to understanding the future of life on our planet such as the climate community.

However significant challenges arise as hardware adapts to the end of Moore's
Law\cite{exascale:workshop:2011}.  The revolution occurring in the hardware architecture
has completely altered the landscape for scientific computing as a code designed for
distributed memory bulk synchronous model of parallelism may actually run slower on
advanced hardware\cite{Dubey:2014:SSC:2686745.2686756}.

Parallelism was added to Fortran with the addition of coarrays in the 2008
standard\cite{fortran:2008} to enable the migration of codes as hardware evolves.
Significant language features were left out of this early version of coarrays as
identified by \emph{Mellor-Crummy et al}\cite{mellor-crummey:2009:caf2}.  Many of these features
have been adopted in what is likely to be called the 2015 standard of the language\cite{fortran:2015},
such as teams of program images and improved synchronization constructs like events.
However, the Fortran coarray model fails to address heterogeneity in hardware as is already
being seen in HPC computing platforms with the adoption of distributed nodes consisting of
general purpose CPUs with attached accelerator devices like GPUs, for example, in the early
RoadRunner Machine at Los Alamos\cite{RoadRunner} and new machines arriving such as Blue
Waters\cite{blue:waters}.

Current


In this preliminary work we have examined ....
In no way does this represent a thorough examination of these potential features.

CAFe introduces the concept of subimages executing on a hosting image.  CAFe includes:
\begin{itemize}
\item
  Dynamic creation of subimages.
\item
  Dynamic memory allocation and placement on a subimage.
\item
  Explicit addressing of memory on subimages using standard coarray notation.  It follows
  the Partitioned Global Address Space model (PGAS), although with subimages the address
  space is hierahical in the sense that the memory partioning only allows memory exchange
  between a subimage and its hosting image as initiated by the hosting image.
\item
  Task creation and execution on subimages using extended coarray syntax with double
  square brackets \texttt{[[ ]]}.  Task mays be defined in terms of standard \emph{pure}
  Fortran procedures and task execution continues without interuption until completion.
  In addition a Fortran 2015 event may be notified upon completion of the task to allow
  concurrent execution on the subimage and on the hosting image.
\item
  CAFe integrates Fortran 2015 features to allow relatively simple programs to be written
  that employ all of the heterogenous components expected on exascale platforms.
\end{itemize}

\subsection{Limitations}

Possible criticism of this work includes the following:
\begin{itemize}
\item
  The source-to-source transformations that have been developed to implement CAFe
  are rudimentory and have not been optimized.  For example, memory transfers have
  not been aggregated into larger messages to improve performance.  Memory transfer
  is also blocking so that prefetching of data cannot be employed via techniques
  envolving the reordering of statements (code motion) that effectively employed in
  CAF compilers.
\item
  The Laplacian example is in reality a ``toy'' problem.  Real multiphysics codes
  employ hundreds of more variables and would have entirely different performance
  characteristics because of the increased pressure on cache and register usage.
\item
  Existing scientific codes often separate communication into separate modules from
  the computational kernels.  This makes adoption of CAF itself slow (because these
  MPI modules already work fine) and thus additional extensions like CAFe also
  would be slow to adopt. However CAFe constructs can be used in an incremental
  fashion making it easier to adopt
\item
  In reality CAF (and therefore CAFe) are relatively low-level parallel programming
  languages that require the programmer to \emph{explicitly} control the placement
  of memory, communication, and synchronization.  Perhaps higher level languages like
  Chapel would be better to adopt as they could provide an easier programming model
  to the programmer and possibly more avenues for compiler optimization.
\item
  Thorough examination of performance capabilities on real scientific applications
  (or at least scientific ``mini-apps'') has not been attempted.
\item
  Programming models like that proposed by CAFe already exist in the form of a combination
  of MPI and OpenMP (or OpenACC) programs.  The advantage of CAFe --- by being a purely
  language construct --- is that it opens up the possibility of compiler optimizations
  that would otherwise be impossible with a library approach intermixed with compiler directives.
\end{itemize}

\subsection{Future Work}

However, especially with the integration of task-based parallelism with synchronization
events arriving in Fortran 2015, the possibilities are intriguing.  Tasks plus the
dependencies represented by events suggest a correspondence with the Open Community
Runtime (OCR) libraries.  In OCR, the entire program must be broken into a set of tasks
represented by a directed acycic graph (DAG).  In OCR, tasks are available for executing
when all of their input dependencies are satisfied, such occurs when computation of a new
interation of data elements have been updated and other upstream tasks have completed.

Tools to automatically convert existing codes to run under the OCR model faces challenges.  For
example, the hundreds of MPI functions would have to be semantically understood by the tools,
integrated with existing OpenACC directives (for example), a DAG generaged for the complete
program, and then transformed into an OCR program.

An intriguing \emph{possibility} exists for automatic conversion of CAFe codes to OCR exists:
\begin{itemize}
\item
  CAF codes have well defined boundaries (called segment boundaries) indicating where new
  OCR tasks must be created.
\item
  CAF has many fewer library routines (primarily collectives) that must be converted.
\item
  CAF has events which already define some of the dependencies necessary for the creation
  of OCR tasks.
\item
  CAFe introduces the notion of task based parallelism (in addition to the existing
  Fortran features like \texttt{do concurrent}.
\end{itemize}

In the future we hope to examine \emph{if} the possibility exists for CAFe codes to be
automatically converted to programs employing the Open Community Runtime.

\begin{comment}
These choices often hide the opportunity for
optimizations by the compiler \cite{Dubey:2014:SSC:2686745.2686756}.
\end{comment}

%
% This could be part of conclusions
%

%%Note that the use of halo cells is the normal way that large and complex MPI and CAF programs are implemented.

\subsubsection{Benefits.}
LOPe proposes to formalize the common, halo software pattern in language syntax, thus providing the
compiler with access to halo information in order to spread computation over more hardware
resources, improve performance, and to reduce complexity for the programmer.  Furthermore, LOPe
semantics provide important \emph{language restrictions} that remove the possibility of race conditions
that occur when multiple threads have write access to overlapping data regions.

\subsubsection{Limitations.}
LOPe only supports regular structured grids through Fortran multi-dimensional arrays and a
corresponding multi-dimensional processor layout.  It does not allow the composability of stencils
required by non-linear physics operators, nor does it provide automatic support for the storage of
intermediate results resulting from multiple intermediate update steps.  Adaptive Mesh Refinement
(AMR) Shift Calculus provides a generalized abstraction that addresses many of these concerns
(see\cite{Dubey:2014:SSC:2686745.2686756} and references therein).  However, it may be possible to
support AMR in LOPe through locally-structured grid methods based on the work of Berger and
Oliger\cite{colella2007performance}.  In this instance, LOPe could be used to update the regular
array regions in each rectangular patch.

By implementing LOPe we have demonstrated that LOPe can be used to easily and succinctly code
the stencil algorithms that are common to many areas of science, and furthermore, that LOPe is
suitable for transformation to languages like OpenCL that support heterogeneous computing.  It
remains to history to ascertain if LOPe is sufficiently general purpose to be included in a
general-purpose programming language or if it is better suited to remain as a DSL and to be used as a
special-purpose preprocessing tool.
