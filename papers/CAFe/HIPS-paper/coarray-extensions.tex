\section{Coarray Fortran Extensions}

Topics highlighted in this section are: 1. Distributed memory array allocation;
2. Explicit memory placement; 3. Remote memory transfer; and 4. Remote execution.  This
description is within the context of extensions to Fortran; as shorthand, these extensions
are referred to as CAFe, for Coarray Fortran extensions.  CAFe is complementary to
previous work extending coarray Fortran\cite{mellor-crummey:2009:caf2,jin:2011:caf2}.


\subsection{Subimages}

We first introduce the important new concept of a \emph{CAFe subimage}.  Fortran images
are a collection of distributed memory processes that all run the same program.  CAFe
extends the concept of a Fortran image by allowing images to be hierarchical; by this we
mean that an image \emph{may} host a subimage (or several subimages).  It is important to
note that a subimage is not visible to Fortran images other than its hosting image.
Subimages also execute differently than normal images and may even execute on different
non-homogeneous hardware, e.g., an attached accelerator device.  Subimages are task based
while images all execute a Single Program but with different (Multiple) Data (SPMD).  A
task can be given to a subimage, but execution on the subimage terminates once the task is
finished.  Memory on a subimage is permanent, however, and must be explicitly allocated
and deallocated.

A programmer requests a subimage by executing the new CAFe function,
\begin{verbatim}
   device = GET_SUBIMAGE(device_id)
\end{verbatim}
where the integer argument represents an attached hardware device (or perhaps a separate
process or a team of threads; it is the compilers responsibility to determine precisely
what a subimage means in terms of the software and hardware environment under its
control).  If the function fails (e.g., the requested device is unavailable) it returns
the local image number of the process that is executing the current program, obtained by a
call to the Fortran 2008 function \texttt{this\_image()}.  Returning the current image if
the \texttt{GET\_SUBIMAGE} fails, allows program execution to proceed correctly even if
there are no attached devices.

Please note that throughout this paper, text appearing in all caps (such as
\texttt{GET\_SUBIMAGE}) indicates new syntax or functionality extended by CAFe.

Once a variable representing a subimage has been obtained, it can be used within a program
to allocate memory, transfer memory, and execute tasks.  This functionality is described below.


\subsection{Distributed Memory Array Declaration}

In Fortran, arrays that are visible to other program images must be declared with the
codimension attribute, for example,
\begin{verbatim}
 real, allocatable :: U(:,:)[:], V(:,:)[:]
\end{verbatim}
declares that coarrays \texttt{U} and \texttt{V} are allocatable with a rank of two and a
corank of 1.  In Fortran, square brackets \texttt{[ ]} are used to indicate operations
(possibly expensive) on distributed memory where parentheses \texttt{( )} are used to
select specific array elements; square brackets, on the other hand, denote the
\emph{location} of the array or array elements selected.

When declared thusly, coarrays must subsequently be allocated on all program images.  With
CAFe, this declaration also allows memory to be allocated on a subimage, however memory
allocation on a subimage is not required unless it is specifically used by some task
executing that will be executed on the subimage.


\subsection{Explicit Memory Placement}

As discussed, CAFe allows coarray memory to be conditionally allocated on a subimage.
It should be allocated conditionally because the requested subimage in a \texttt{GET\_SUBIMAGE}
call may not be available.  In addition, not all coarrays need be allocated on each
subimage.  For example, the following code segment allocates memory for coarrays
\texttt{U} and \texttt{V} on all images, but only coarray \texttt{U} is allocated on
the subimage specified by \texttt{device}:
\begin{verbatim}
   allocate(U(M,N)[*], V(M,N)[*])
   if (device \= this_image()) then
     allocate(U(M,N)[*])  [[device]]
   end if
\end{verbatim}
where \texttt{M} and \texttt{N} are constant parameters.  The first allocate statement
allocates coarrays \texttt{U} and \texttt{V} on all program images.  The \texttt{*} symbol
in the allocation is required for the last corank dimension in CAF (in this case there is
only one) to allow for the number of program images to be a runtime parameter, which can
be ascertained with a \texttt{num\_images()} function call.  If \texttt{device} is
available, its numeric value will be different from \texttt{this\_image()} and thus
coarray \texttt{U} will also be allocated on the device.  Note that placement of the
memory is specified by the use of double square bracket notation \texttt{[[ ]]}.  Like
single square brackets, double square brackets indicate something special (and possibly
expensive) is to occur, in this case possibly remote memory allocation.

Deallocation of subimage memory is similar to allocation,
\begin{verbatim}
   if (device \= this_image()) then
     deallocate(U)  [[device]]
   end if
\end{verbatim}


\subsection{Remote Memory Transfer}

Once memory is allocated on the device, it can be initialized by copying memory from the
hosting image to the device.  This is explicitly done with normal CAF syntax.  For example,
\begin{verbatim}
  U[device] = 3.14
\end{verbatim}
assigns 3.14 to all of the array elements of \texttt{U} located on \texttt{device}.
Specific array elements can also be transferred, 
\begin{verbatim}
  U(1,:) = U(1,:)[device]
  U(M,:) = U(M,:)[device]
\end{verbatim}
where the first and last columns of \texttt{U} are copied from the device to the hosting image.

CAFe restricts memory transfer between a subimage and its hosting image only; transferring
memory to a subimage hosted by another image is not allowed.  In addition, memory transfer
can only be initiated by the hosting image.  Thus code executing on a subimage cannot use
coarray notation to select memory on another subimage nor on its host.

\subsection{Remote Execution}

The final CAFe concept introduced is that of remote execution.  As discussed above,
all CAF images (similar to MPI ranks) execute the same program.  The only way for
an image to execute something different is to conditionally execute a block of code based
on explicitly checking that an executing image's rank (\texttt{this\_image()}) meets some
established criterion.  There currently exists no mechanism for one image to execute a
block of code or a procedure on another image.

However, CAFe allows images to execute tasks on hosted subimages using standard procedure
calls.  For example,
\begin{verbatim}
  call relax(U[device])  [[device]]
\end{verbatim}
executes the subroutine relax, on the subimage device, using array \texttt{U} \emph{located}
on the same subimage.  This follows the same pattern as introduced for remote coarray allocation,
whereby the double square bracket notation indicates \emph{where} the function will execute.
Funtions to be executed on a subimage must be pure procedures (i.e., declared with the Fortran
keyword \texttt{pure}) and scalar formal parameters must be passed by value (i.e., declared with the
\texttt{value} attribute).

CAFe expands on CAF execution semantics by providing a task-based mechanism, where tasks
are defined in terms of pure Fortran procedures.  Since the procedures must be declared
as pure, they cannot perform any I/O or call any impure procedures; nor can they initiate
any communication between the subimage and the hosting image.

In addition, CAFe subimage tasks may also be defined by the body of a Fortran do
concurrent construct and executed on a subimage.  For example, the code segment,
\begin{verbatim}
do concurrent(i=1:N-1)  [[device]]
 begin block
   real :: w = 0.67
   S(i) = (1-w)*T(i) + w*(T(i-1)+T(i+1)/2)
 end block
end do
\end{verbatim}
will execute all of the code within the \texttt{do concurrent} construct on \texttt{device}.

In Fortran, the execution semantics of a \texttt{do concurrent} loop is that the loop
iterates can be executed concurrently in any order.  Note the similarities between this
example and the OpenMP pragma \texttt{!\$omp parallel do, private(w)}.  The use of the
Fortran block construct to declare private variables allows a natural and clear way to
distinguish between variables that are private to a ``thread'' (although in the example
above, the ``private'' distinction for the variable \texttt{w} is unnecessary because it
is a constant for all loop iterations).

(NOTE FOR CRAIG: need to read the standard to see if a block construct can be used in this
way. ALSO, there is a lot more work here to think about how do concurrent merges with
OpenMP and OpenACC with regards to synchronization, barriers, teams, atomics, , critical
sections, ...)


\subsection{Integration with Coarray Standard Features}

Want to address: Barriers and teams primarily



%\input{coarray-comparison}



%%A team of images is a set of images that can readily execute independently of other images (from N2007)

%%An allocated allocatable coarray is established in the team in which it was allocated


%%\subsection{Execution Semantics and Memory Management}

%%This section describes the hierarchical memory layout and how memory consistency between the 3-levels of memory is maintained.  It describes what is the compiler's responsibility and what is the programmer's responsibility.

%% Completion of a do concurrent construct indicates that all executing threads (if a threading model is used by the compiler) have completed and that all memory on the executing subimage is in a consistent state.

%%The {\tt HALO} function returns a copy of the 3x3 region of {\tt a} and its surrounding neighbors.  The {\tt convolve} function is free of race conditions because of the copy semantics of {\tt HALO} and the implied synchronization of the {\tt CONCURRENT} attribute, whereby no output variables can be updated before all threads have completed execution.  In addition, while any thread may load from an extended region about \emph{its} element with the {\tt HALO} function, it may only store into its own elemental location.


%% A note from a conversation with Matt regarding memory management
%%

%The Fortran language has much tighter restrictions on aliasing than does C.
%So unless a variable has the pointer or target attribute, it cannot be aliased.
%Thus the compiler is able to aggressively optimized for memory movement between
%the CPU and accelerator.  However, because the design philosophy of coarrays
%is that memory transfer between images can be expensive, the programmer must
%explicitly transfer memory between images with explicit syntax with square
%bracket notation, i.e., $a[1] = a[2]$.  So we allow the compiler to manage
%memory within an image but require the use of {\tt halo\_exchange} for the
%transfer of halo memory between images.


%Fortran currently supports:

%1. Array syntax: e.g., C = A + B, where A, B, C are arrays.  Note that this is implicitly a loop structure, but that no loop indices need be provided.  Also the programmer need not specify where in memory these arrays reside.  Thus this high level syntax allows the compiler more freedom in both memory placement (even across distributed memory nodes) and in runtime code execution (individual array element may be computed by different hardware threads).  This is a simple example and it is a research question as to what compiler directives would be useful for memory placement and other directions to the compiler for efficient code generation.

%2. Pure procedures:  Fortran has syntax for specifying procedures that have no side effects during execution.  Specifying code that is side-effect free code is important information to provide to the compiler so that it can generate efficient multi-threaded code.

%3. Pure elemental procedures: Fortran has syntax for specifying procedures that take only scalar arguments, but may be applied across array elements.  Elemental procedures are ideal for writing code to be executed within a hardware thread.  They resemble OpenCL kernels, but are simpler because they leave all indexing up to the compiler.

%We have determined that additional syntax is needed, in addition to the three language features described above, to allow programmers the ability to express code in Fortran to be targeted for multi-threaded hardware architectures like GPUs.  This additional syntax is provided by functions that return a copy of a small region of memory surrounding an array element (as seen within an elemental procedure) and with functions for thread synchronization.  This additional syntax will allow pure procedures to perform stencil and other convolution-like operations on a copy of memory, synchronize, then store the computed results back to the array element associated with the given thread.

%In addition Fortran has syntax like the target attribute the specifies when variables can be aliased.  This allows for much easier program analysis as the compiler knows that ordinary variables cannot be aliased.  Fortran also has excellent facilities for interoperability with C so that programming in a mixed language environment is easily accomplished, including interoperability with native Fortran arrays.

%
% This could be part of conclusions
%

%%Note that the use of halo cells is the normal way that large and complex MPI and CAF programs are implemented.  LOPe proposes to formalize this common pattern into the Fortran language allowing the compiler access to this information in order to spread computation over more hardware resources, improve performance, and to reduce complexity for the programmer.
